{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"mixtral:8x7b\"\n",
    "#MODEL = \"llama2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Ensure this line is called before accessing the environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API Key:\", OPENAI_API_KEY)  # Check if the API key is being loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 11, 'total_tokens': 27}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-60870133-acd3-4e2d-83f7-1ef6d6193266-0', usage_metadata={'input_tokens': 11, 'output_tokens': 16, 'total_tokens': 27})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(api_key=OPENAI_API_KEY,model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    model.invoke(\"what is the capital on india\")\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings\n",
    "\n",
    "model.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'MLConcepts.pdf', 'page': 0}, page_content='ML Concepts\\nBehrooz Azarkhalili1\\n1Life Language Processing Lab, University of California, Berkeley\\n1azarkhalili@behrooz.tech\\nContents\\n1 Fundamental Concepts in Machine Learning 2\\n1.1 Loss Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.1 Classification Losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.2 Regression Losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.2 Performance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.2.1 Classification Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.2.2 Regression Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3 Bias and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3.1 Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3.2 Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.3.3 Trade-off . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2 Training, Validation, and Testing of Machine Learning Models 5\\n2.1 Training the Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Validating the Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nPreprint. Under review.'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 1}, page_content='1 Fundamental Concepts in Machine Learning\\nIn machine learning, understanding the concepts of loss, metrics, bias, and variance is essential for\\ndeveloping, evaluating, and improving models. These concepts are central to diagnosing model\\nperformance and ensuring that the model predictions are accurate and reliable.\\n1.1 Loss Functions\\nLoss Functions measure the discrepancy between the actual values and the predictions made by\\na model. They quantify how well the model performs; the lower the loss, the better the model’s\\npredictions.\\n1.1.1 Classification Losses\\n•Cross-Entropy Loss (Log Loss) : Measures the performance of a classification model\\nwhose output is a probability value between 0 and 1. Cross-entropy loss increases as the\\npredicted probability diverges from the actual label.\\nCross-Entropy Loss =−1\\nNNX\\ni=1yilog(ˆyi) + (1 −yi) log(1 −ˆyi)\\nExample\\nLet’s consider a binary classification problem with 10 samples and their predicted probabili-\\nties and true labels:\\nSample Predicted Probability True Label Log Loss\\n1 0 .9 1 −log(0.9)\\n2 0 .1 0 −log(0.9)\\n3 0 .8 1 −log(0.8)\\n4 0 .4 0 −log(0.6)\\n5 0 .7 1 −log(0.7)\\n6 0 .2 0 −log(0.8)\\n7 0 .6 1 −log(0.6)\\n8 0 .3 0 −log(0.7)\\n9 0 .5 1 −log(0.5)\\n10 0 .1 0 −log(0.9)\\nThe average log loss can be computed by averaging these values.\\n•Hinge Loss : Used primarily for binary classification tasks. It is intended for use with\\nSupport Vector Machine (SVM) models.\\nHinge Loss =1\\nNNX\\ni=1max(0 ,1−yiˆyi)\\nExample\\nConsider 10 samples with true labels yi∈ {− 1,1}and predicted scores ˆyi:\\nSample Predicted Score True Label Hinge Loss\\n1 0 .9 1 max(0 ,1−0.9)\\n2 −0.1 −1 max(0 ,1−0.1)\\n3 0 .8 1 max(0 ,1−0.8)\\n4 −0.4 −1 max(0 ,1−0.6)\\n5 0 .7 1 max(0 ,1−0.7)\\n6 −0.2 −1 max(0 ,1−0.8)\\n7 0 .6 1 max(0 ,1−0.6)\\n8 −0.3 −1 max(0 ,1−0.7)\\n9 0 .5 1 max(0 ,1−0.5)\\n10 −0.1 −1 max(0 ,1−0.9)\\nThe average hinge loss can be computed by averaging these values.\\n2'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 3}, page_content='1.1.2 Regression Losses\\n•Mean Squared Error (MSE) : The average of the squares of the errors—that is, the average\\nsquared difference between the estimated values and the actual value.\\nMSE =1\\nNNX\\ni=1(yi−ˆyi)2\\nExample\\nGiven 10 sample points:\\nTrue Value Predicted Value Squared Error\\n3 2 .8 (3 −2.8)2= 0.04\\n1 1 .2 (1 −1.2)2= 0.04\\n4 3 .9 (4 −3.9)2= 0.01\\n2 2 .1 (2 −2.1)2= 0.01\\n5 4 .8 (5 −4.8)2= 0.04\\n6 6 .2 (6 −6.2)2= 0.04\\n3.5 3 .7 (3 .5−3.7)2= 0.04\\n2.5 2 .3 (2 .5−2.3)2= 0.04\\n4.5 4 .6 (4 .5−4.6)2= 0.01\\n5.5 5 .4 (5 .5−5.4)2= 0.01\\nThe average MSE is:\\nMSE =0.04 + 0 .04 + 0 .01 + 0 .01 + 0 .04 + 0 .04 + 0 .04 + 0 .04 + 0 .01 + 0 .01\\n10= 0.028\\n•Mean Absolute Error (MAE) : The average of the absolute differences between predictions\\nand actual observations. It provides a measure of how wrong the predictions are.\\nMAE =1\\nNNX\\ni=1|yi−ˆyi|\\nExample\\nUsing the same 10 sample points as above, the MAE is calculated as follows:\\nTrue Value Predicted Value Absolute Error\\n3 2 .8 |3−2.8|= 0.2\\n1 1 .2 |1−1.2|= 0.2\\n4 3 .9 |4−3.9|= 0.1\\n2 2 .1 |2−2.1|= 0.1\\n5 4 .8 |5−4.8|= 0.2\\n6 6 .2 |6−6.2|= 0.2\\n3.5 3 .7 |3.5−3.7|= 0.2\\n2.5 2 .3 |2.5−2.3|= 0.2\\n4.5 4 .6 |4.5−4.6|= 0.1\\n5.5 5 .4 |5.5−5.4|= 0.1\\nThe average MAE is:\\nMAE =0.2 + 0.2 + 0.1 + 0.1 + 0.2 + 0.2 + 0.2 + 0.2 + 0.1 + 0.1\\n10= 0.16\\n1.2 Performance Metrics\\nPerformance Metrics evaluate the effectiveness of a model using the test data. Unlike loss functions,\\nmetrics are used to interpret model performance and are not always differentiable.\\n3'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 4}, page_content='1.2.1 Classification Metrics\\n•Accuracy : The ratio of correctly predicted observations to the total observations. Best used\\nwhen there are equal numbers of samples in each class.\\nAccuracy =Number of Correct Predictions\\nTotal Number of Predictions\\nExample\\nGiven 10 samples with 8 correct predictions:\\nAccuracy =8\\n10= 0.8\\n•Precision : Precision is the ratio of correctly predicted positive observations to the total\\npredicted positives.\\nPrecision =True Positives\\nTrue Positives + False Positives\\n•Recall : Recall (Sensitivity) is the ratio of correctly predicted positive events to all actual\\npositives.\\nRecall =True Positives\\nTrue Positives + False Negatives\\nExample\\nFor 10 samples with:\\nTrue Positives False Positives True Negatives False Negatives\\n4 1 3 2\\nPrecision and Recall are:\\nPrecision =4\\n4 + 1= 0.8\\nRecall =4\\n4 + 2= 0.6667\\n•F1 Score : The weighted harmonic average of Precision and Recall. This score takes both\\nfalse positives and false negatives into account.\\nF1 Score = 2·Precision ·Recall\\nPrecision +Recall\\nExample\\nGiven Precision = 0.8 and Recall = 0.6667:\\nF1 Score = 2·0.8·0.6667\\n0.8 + 0.6667= 0.727\\n1.2.2 Regression Metrics\\n•Mean Squared Error (MSE) : The average of the squares of the errors—that is, the average\\nsquared difference between the estimated values and the actual value.\\n•Mean Absolute Error (MAE) : The average of the absolute differences between predictions\\nand actual observations.\\n1.3 Bias and Variance\\n1.3.1 Bias\\nBias refers to the error introduced by approximating a real-world problem, which may be complicated,\\nby a much simpler model. High bias can cause an algorithm to miss the relevant relations between\\nfeatures and target outputs (underfitting).\\n4'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 5}, page_content='1.3.2 Variance\\nVariance refers to the amount by which the model’s prediction would change if different training data\\nwas used. High variance can cause a model to model the random noise in the training data, rather\\nthan the intended outputs (overfitting).\\nExamples\\nHigh Bias Scenario : A model that predicts housing prices using only the size of the house, ignoring\\nother features like age, location, and number of rooms, may have high bias.\\nExamples\\nHigh Variance Scenario : A model that predicts stock prices by fitting a complex polynomial that\\npasses through every single data point in the training data is likely to have high variance.\\n1.3.3 Trade-off\\nThe Bias-Variance Tradeoff is a central problem in supervised learning. Ideally, one wants to choose\\na model that accurately captures the regularities in its training data but also generalizes well to unseen\\ndata. Unfortunately, a model with very low bias must pay for it with high variance and vice versa.\\n2 Training, Validation, and Testing of Machine Learning Models\\nIn machine learning, the development and deployment of models involve three critical phases:\\ntraining, validation, and testing. Each phase serves a distinct purpose in ensuring that the model\\nperforms well on unseen data, thereby generalizing effectively. Here’s a detailed explanation of each\\nphase:\\n2.1 Training the Model\\nTraining involves feeding a machine learning algorithm with a dataset and allowing it to learn the\\nrelationships between the features (input variables) and the target (output variable). The goal is to\\noptimize the model parameters to minimize the error on the training data.\\nSteps to Train the Model:\\n1.Data Preparation:\\n• Split the dataset into features (X) and target (y).\\n• Normalize or standardize the features if necessary.\\n• Optionally, handle missing values, categorical variables, and outliers.\\n2.Model Selection:\\n•Choose a suitable machine learning algorithm (e.g., linear regression, decision trees,\\nneural networks) based on the problem (classification or regression).\\n3.Initialization:\\n• Initialize the model parameters (weights and biases).\\n4.Training:\\n•Use an optimization algorithm (e.g., gradient descent) to iteratively update the model\\nparameters.\\n•At each iteration (epoch), the algorithm computes the predictions, calculates the loss\\nusing a loss function (e.g., mean squared error for regression, cross-entropy for classifi-\\ncation), and updates the parameters to minimize the loss.\\n5'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 6}, page_content='Example\\nFor a linear regression model, the training process involves finding the optimal weights wand bias b\\nthat minimize the mean squared error:\\nMSE =1\\nNNX\\ni=1(yi−(w·xi+b))2\\nwherexiare the features, and yiare the true values.\\n2.2 Validating the Model\\nValidation involves assessing the model’s performance on a separate dataset (validation set) that was\\nnot used during training. This helps in tuning the model’s hyperparameters and preventing overfitting.\\nSteps to Validate the Model:\\n1.Data Splitting:\\n•Split the training dataset into the new training alongside validation sets (e.g., 80%\\ntraining, 20% validation).\\n2.Hyperparameter Tuning:\\n• Use techniques like grid search or random search to find the best hyperparameters.\\n•Train the model on the training set with different hyperparameter configurations and\\nevaluate on the validation set.\\n3.Cross-Validation:\\n•Perform k-fold cross-validation to ensure that the model’s performance is consistent\\nacross different subsets of the data. In k-fold cross-validation, the dataset is divided\\ninto k subsets, and the model is trained k times, each time using a different subset as\\nthe validation set and the remaining subsets as the training set.\\nExample\\nFor a decision tree, hyperparameters like max_depth and min_samples_split can be tuned using the\\nvalidation set to find the best configuration that balances bias and variance.\\n3. Testing or Evaluating the Model\\nTesting involves assessing the final model’s performance on a test dataset that was not used during\\ntraining or validation. This gives an unbiased estimate of the model’s performance on unseen data.\\nSteps to Test the Model:\\n1.Data Splitting:\\n•Split the dataset into training, validation, and test sets (e.g., 70% training, 15% valida-\\ntion, 15% test).\\n2.Final Model Training:\\n•Train the model on the combined training and validation sets using the best hyperpa-\\nrameters found during validation.\\n3.Performance Evaluation:\\n•Evaluate the model on the test set using appropriate metrics (e.g., accuracy, precision,\\nrecall, F1 score for classification; mean squared error, R-squared for regression).\\nExample: For a classification model, the performance on the test set can be evaluated using the\\nconfusion matrix to calculate accuracy, precision, recall, and F1 score:\\nAccuracy =True Positives + True Negatives\\nTotal Number of Samples\\n6'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 7}, page_content='Precision =True Positives\\nTrue Positives + False Positives\\nRecall =True Positives\\nTrue Positives + False Negatives\\nF1 Score = 2·Precision ·Recall\\nPrecision +Recall\\n2.3 Summary\\n•Training : Learn model parameters using the training dataset.\\n•Validation : Tune hyperparameters and prevent overfitting using the validation dataset.\\n•Testing : Evaluate final model performance using the test dataset.\\n7')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"MLConcepts.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you cant answer the \n",
      "question, reply \"I am sorry its out of my domain\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you cant answer the \n",
    "question, reply \"I am sorry its out of my domain\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\",question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ricky.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\":\"The name i was given was Ricky\",\n",
    "        \"question\":\"what is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "Vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages, \n",
    "    embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'MLConcepts.pdf', 'page': 0}, page_content='ML Concepts\\nBehrooz Azarkhalili1\\n1Life Language Processing Lab, University of California, Berkeley\\n1azarkhalili@behrooz.tech\\nContents\\n1 Fundamental Concepts in Machine Learning 2\\n1.1 Loss Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.1 Classification Losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.2 Regression Losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.2 Performance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.2.1 Classification Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.2.2 Regression Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3 Bias and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3.1 Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.3.2 Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.3.3 Trade-off . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2 Training, Validation, and Testing of Machine Learning Models 5\\n2.1 Training the Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Validating the Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nPreprint. Under review.'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 1}, page_content='1 Fundamental Concepts in Machine Learning\\nIn machine learning, understanding the concepts of loss, metrics, bias, and variance is essential for\\ndeveloping, evaluating, and improving models. These concepts are central to diagnosing model\\nperformance and ensuring that the model predictions are accurate and reliable.\\n1.1 Loss Functions\\nLoss Functions measure the discrepancy between the actual values and the predictions made by\\na model. They quantify how well the model performs; the lower the loss, the better the model’s\\npredictions.\\n1.1.1 Classification Losses\\n•Cross-Entropy Loss (Log Loss) : Measures the performance of a classification model\\nwhose output is a probability value between 0 and 1. Cross-entropy loss increases as the\\npredicted probability diverges from the actual label.\\nCross-Entropy Loss =−1\\nNNX\\ni=1yilog(ˆyi) + (1 −yi) log(1 −ˆyi)\\nExample\\nLet’s consider a binary classification problem with 10 samples and their predicted probabili-\\nties and true labels:\\nSample Predicted Probability True Label Log Loss\\n1 0 .9 1 −log(0.9)\\n2 0 .1 0 −log(0.9)\\n3 0 .8 1 −log(0.8)\\n4 0 .4 0 −log(0.6)\\n5 0 .7 1 −log(0.7)\\n6 0 .2 0 −log(0.8)\\n7 0 .6 1 −log(0.6)\\n8 0 .3 0 −log(0.7)\\n9 0 .5 1 −log(0.5)\\n10 0 .1 0 −log(0.9)\\nThe average log loss can be computed by averaging these values.\\n•Hinge Loss : Used primarily for binary classification tasks. It is intended for use with\\nSupport Vector Machine (SVM) models.\\nHinge Loss =1\\nNNX\\ni=1max(0 ,1−yiˆyi)\\nExample\\nConsider 10 samples with true labels yi∈ {− 1,1}and predicted scores ˆyi:\\nSample Predicted Score True Label Hinge Loss\\n1 0 .9 1 max(0 ,1−0.9)\\n2 −0.1 −1 max(0 ,1−0.1)\\n3 0 .8 1 max(0 ,1−0.8)\\n4 −0.4 −1 max(0 ,1−0.6)\\n5 0 .7 1 max(0 ,1−0.7)\\n6 −0.2 −1 max(0 ,1−0.8)\\n7 0 .6 1 max(0 ,1−0.6)\\n8 −0.3 −1 max(0 ,1−0.7)\\n9 0 .5 1 max(0 ,1−0.5)\\n10 −0.1 −1 max(0 ,1−0.9)\\nThe average hinge loss can be computed by averaging these values.\\n2'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 5}, page_content='1.3.2 Variance\\nVariance refers to the amount by which the model’s prediction would change if different training data\\nwas used. High variance can cause a model to model the random noise in the training data, rather\\nthan the intended outputs (overfitting).\\nExamples\\nHigh Bias Scenario : A model that predicts housing prices using only the size of the house, ignoring\\nother features like age, location, and number of rooms, may have high bias.\\nExamples\\nHigh Variance Scenario : A model that predicts stock prices by fitting a complex polynomial that\\npasses through every single data point in the training data is likely to have high variance.\\n1.3.3 Trade-off\\nThe Bias-Variance Tradeoff is a central problem in supervised learning. Ideally, one wants to choose\\na model that accurately captures the regularities in its training data but also generalizes well to unseen\\ndata. Unfortunately, a model with very low bias must pay for it with high variance and vice versa.\\n2 Training, Validation, and Testing of Machine Learning Models\\nIn machine learning, the development and deployment of models involve three critical phases:\\ntraining, validation, and testing. Each phase serves a distinct purpose in ensuring that the model\\nperforms well on unseen data, thereby generalizing effectively. Here’s a detailed explanation of each\\nphase:\\n2.1 Training the Model\\nTraining involves feeding a machine learning algorithm with a dataset and allowing it to learn the\\nrelationships between the features (input variables) and the target (output variable). The goal is to\\noptimize the model parameters to minimize the error on the training data.\\nSteps to Train the Model:\\n1.Data Preparation:\\n• Split the dataset into features (X) and target (y).\\n• Normalize or standardize the features if necessary.\\n• Optionally, handle missing values, categorical variables, and outliers.\\n2.Model Selection:\\n•Choose a suitable machine learning algorithm (e.g., linear regression, decision trees,\\nneural networks) based on the problem (classification or regression).\\n3.Initialization:\\n• Initialize the model parameters (weights and biases).\\n4.Training:\\n•Use an optimization algorithm (e.g., gradient descent) to iteratively update the model\\nparameters.\\n•At each iteration (epoch), the algorithm computes the predictions, calculates the loss\\nusing a loss function (e.g., mean squared error for regression, cross-entropy for classifi-\\ncation), and updates the parameters to minimize the loss.\\n5'),\n",
       " Document(metadata={'source': 'MLConcepts.pdf', 'page': 6}, page_content='Example\\nFor a linear regression model, the training process involves finding the optimal weights wand bias b\\nthat minimize the mean squared error:\\nMSE =1\\nNNX\\ni=1(yi−(w·xi+b))2\\nwherexiare the features, and yiare the true values.\\n2.2 Validating the Model\\nValidation involves assessing the model’s performance on a separate dataset (validation set) that was\\nnot used during training. This helps in tuning the model’s hyperparameters and preventing overfitting.\\nSteps to Validate the Model:\\n1.Data Splitting:\\n•Split the training dataset into the new training alongside validation sets (e.g., 80%\\ntraining, 20% validation).\\n2.Hyperparameter Tuning:\\n• Use techniques like grid search or random search to find the best hyperparameters.\\n•Train the model on the training set with different hyperparameter configurations and\\nevaluate on the validation set.\\n3.Cross-Validation:\\n•Perform k-fold cross-validation to ensure that the model’s performance is consistent\\nacross different subsets of the data. In k-fold cross-validation, the dataset is divided\\ninto k subsets, and the model is trained k times, each time using a different subset as\\nthe validation set and the remaining subsets as the training set.\\nExample\\nFor a decision tree, hyperparameters like max_depth and min_samples_split can be tuned using the\\nvalidation set to find the best configuration that balances bias and variance.\\n3. Testing or Evaluating the Model\\nTesting involves assessing the final model’s performance on a test dataset that was not used during\\ntraining or validation. This gives an unbiased estimate of the model’s performance on unseen data.\\nSteps to Test the Model:\\n1.Data Splitting:\\n•Split the dataset into training, validation, and test sets (e.g., 70% training, 15% valida-\\ntion, 15% test).\\n2.Final Model Training:\\n•Train the model on the combined training and validation sets using the best hyperpa-\\nrameters found during validation.\\n3.Performance Evaluation:\\n•Evaluate the model on the test set using appropriate metrics (e.g., accuracy, precision,\\nrecall, F1 score for classification; mean squared error, R-squared for regression).\\nExample: For a classification model, the performance on the test set can be evaluated using the\\nconfusion matrix to calculate accuracy, precision, recall, and F1 score:\\nAccuracy =True Positives + True Negatives\\nTotal Number of Samples\\n6')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = Vectorstore.as_retriever()\n",
    "retriever.invoke(\"Machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain response: Machine learning is a field of study that involves developing, evaluating, and improving models by understanding concepts such as loss, metrics, bias, and variance. It involves training machine learning algorithms with data to learn relationships between features and target variables, in order to make accurate predictions on unseen data.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "chain = (\n",
    "    {\n",
    "        \"context\":itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model \n",
    "    | parser\n",
    "    \n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": \"What is machine learning?\"})\n",
    "print(\"Chain response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are loss functions?\n",
      "Answer: Loss functions measure the discrepancy between the actual values and the predictions made by a model. They quantify how well the model performs; the lower the loss, the better the model's predictions.\n",
      "\n",
      "Question: what is F1 score?\n",
      "Answer: F1 Score is the weighted harmonic average of Precision and Recall. It takes both false positives and false negatives into account.\n",
      "\n",
      "Question: what is trade-off ?\n",
      "Answer: The trade-off refers to the Bias-Variance Tradeoff in supervised learning, where one wants to choose a model that accurately captures the regularities in its training data but also generalizes well to unseen data. Unfortunately, a model with very low bias must pay for it with high variance and vice versa.\n",
      "\n",
      "Question: How to train the model ?what is the capital of India?\n",
      "Answer: How to train the model: To train the model, you need to follow these steps:\n",
      "1. Data Preparation: Split the dataset into features and target, normalize or standardize the features if necessary, handle missing values, categorical variables, and outliers.\n",
      "2. Model Selection: Choose a suitable machine learning algorithm based on the problem.\n",
      "3. Initialization: Initialize the model parameters.\n",
      "4. Training: Use an optimization algorithm to iteratively update the model parameters by computing predictions, calculating loss, and updating parameters to minimize the loss.\n",
      "\n",
      "I am sorry it's out of my domain to answer the question about the capital of India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"what are loss functions?\",\n",
    "    \"what is F1 score?\",\n",
    "    \"what is trade-off ?\",\n",
    "    \"How to train the model ?\"\n",
    "    \"what is the capital of India?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question':question})}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
